---
title: "Proyecto Final"
author: "Grupo AGMJ"
date: "12/3/2023"
output: html_document
---

#Algoritmos utilizado: Regresion logistica y RandomForest

```{r setup, include=FALSE}
#install.packages("knitr")
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

#librerias
```{r}
library(ggplot2)
library(GGally)
library(mvnTest)
library(vcd)
library(corrplot)
library(car)
library(MVN)
library(PASWR)
library(coin)
library(survival)
library(agricolae)
library(cvTools)
library(pROC)
library(boot)
library(randomForest)
library(caret)
library(factoextra)
```

#Carga DataSet
```{r}
data_diab <- read.csv("diabetes-dataset.csv", header = TRUE, dec = ".", sep = ",", na.strings = c("", "NA", "N/A", "NULL"))
data_diab <- na.omit(data_diab)

data_diab <- data.frame(data_diab)
data_diab$Outcome <- factor(data_diab$Outcome)
```

#Variables del DataSet
```{r}
str(data_diab)
```

#Analisis exploratorio
```{r}
EDA(data_diab$Pregnancies)
EDA(data_diab$Glucose)
EDA(data_diab$BloodPressure)
EDA(data_diab$SkinThickness)
EDA(data_diab$Insulin)
EDA(data_diab$BMI)
EDA(data_diab$DiabetesPedigreeFunction)
EDA(data_diab$Age)
```

#Analisis de Bigotes
```{r}
ggplot(data = data_diab, mapping = aes(x = Outcome, y = Pregnancies)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = Glucose)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = BloodPressure)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = SkinThickness)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = Insulin)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = BMI)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = DiabetesPedigreeFunction)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = Age)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

```

```{r}
royston_test <- mvn(data = data_diab[,-9], mvnTest = "royston")
royston_test$multivariateNormality

hz_test <- mvn(data = data_diab[,-9], mvnTest = "hz")
hz_test$multivariateNormality
```

# El modelo Mann-Whitney lo utilizamos para comparar las medianas de dos grupos independientes en una variable ordinal o continua no paramétrica.

# El modelo Kruskal-Wallis lo utilizamos para comparar las medianas de tres o más grupos independientes en una variable ordinal o continua no paramétrica.
```{r}
# Realizar la prueba de Mann-Whitney para datos no pareados
wilcox.test(data_diab$Glucose, data_diab$Pregnancies)

# Realizar la prueba de Kruskal-Wallis
kruskal.test(data_diab$BMI, data_diab$DiabetesPedigreeFunction)
```
#Test de Normalidad
```{r}
par(mfcol = c(2, 8))
for (k in 1:8) {
  j0 <- names(data_diab)[k]
  x0 <- seq(min(data_diab[, k]), max(data_diab[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(data_diab$Outcome)[i]
    x <- data_diab[data_diab$Outcome == i0, j0]
    hist(x, proba = T, col = grey(0.8), main = paste( i0), xlab = j0)
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}
```

#Modelo de Correlacion
```{r}
correlations <- cor(data_diab[,1:8])
corrplot(correlations, method="circle")
```

#Tabla de Correlacion
```{r}
ggpairs(data_diab)
```

#Modelo de analisis de regresion
```{r}
modelo <- glm(Outcome ~ ., data = data_diab, family = binomial)
summary(modelo)
```

#Step backward feature selection
```{r}
step(modelo, direction = "backward")
```

#Division de DataSet
```{r}
set.seed(1)
row.number = sample(1:nrow(data_diab), 0.6*nrow(data_diab))
train = data_diab[row.number,]
test = data_diab[-row.number,]
dim(train)
dim(test)

```

```{r}
# Modelo de regresión logistica
log_reg_model = glm(Outcome ~ . -SkinThickness, data = train, family = binomial)

# Modelo de Random Forest
rf_model <- randomForest(Outcome ~ . -SkinThickness, data = train, ntree = 100)
```


#Validacion Cruzada
```{r}

cat("Regresión logistica", "\n", "\n")
# Validación cruzada con 10 pliegues
cv_log_reg <- cv.glm(train, log_reg_model, K = 10)

# Obtener la media y la desviación estándar del error de predicción
mean_error_logreg <- mean(cv$delta) # media del error de predicción
sd_error_logreg <- sd(cv$delta)     # desviación estándar del error de predicción

# Imprimir los resultados
cat("Regresión Logistica", "\n", "\n")
cat("Media del error de predicción: ", mean_error*100,"%", "\n")
cat("Desviación estándar del error de predicción: ", sd_error, "\n")


cat("\n","\n", "Random Forest", "\n", "\n")
ctrl <- trainControl(method = "cv", number = 10)
cv_results <- cv(rf_model, control = ctrl)
```

#Area bajo la curva
```{r}
# Ajustar el modelo al conjunto de datos de entrenamiento
fit <- predict(log_reg_model, train, type = "response")

# Calcular el área bajo la curva ROC utilizando el conjunto de datos de entrenamiento
auc <- roc(train$Outcome, fit)

# Imprimir el valor del área bajo la curva ROC
cat("Área bajo la curva ROC: ", auc$auc, "\n")
```

#Resumen del modelo de regresión logistica
```{r}
cat("Regresión logistica","\n","\n")
summary(log_reg_model)
cat("\n","\n","Random forest","\n","\n")
summary(rf_model)
```

#Coeficientes de regresion logistica
```{r}
options(scipen = 999) #Para evitar que mis datos me salgan en notación
#científica
exp(cbind(OR=coef(log_reg_model),confint(log_reg_model)))
```

#variance inflation factor
```{r}
vif(log_reg_model)
```

#Matriz de Confusion
```{r}
predicciones <- ifelse(test = log_reg_model$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion <- table(log_reg_model$model$Outcome, predicciones,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion
```
```{r}
mosaic(matriz_confusion, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
```
#Resultados
```{r}
acierto_global <- ((725+208)/(725+208+185+82))*100
cat("acierto global: ",acierto_global,"\n")

error_global <- 100 - acierto_global
cat("error global: ",error_global,"\n")

acierto_positivo <- (208/(208+82))*100
cat("acierto positivo: ",acierto_positivo,"\n")

acierto_negativo <- (725/(185+725))*100
cat("acierto negativo: ",acierto_negativo,"\n")
```

#Matriz de confusion (Data: Test) 
```{r}
glm.pred <- ifelse(glm.probs > 0.5, "1", "0")

matriz.test <- table(test$Outcome,glm.pred,
      dnn = c("observaciones", "predicciones"))
matriz.test

mean(glm.pred == test$Outcome)
```
```{r}
mosaic(matriz.test, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
```
#Resultados
```{r}
acierto_global_test <- ((453+160)/(453+160+131+56))*100
cat("acierto global: ",acierto_global_test, "\n")

error_global_test <- 100 - acierto_global_test
cat("error global: ",error_global_test, "\n")

acierto_positivo_test <- (160/(160+56))*100
cat("Acierto positivo: ",acierto_positivo_test, "\n")

acierto_negativo_test <- (453/(131+453))*100
cat("Acierto negativo: ",acierto_negativo_test, "\n")
```

#Algoritmo RandomForest
```{r}
# Evaluamos la precisión del modelo en el conjunto de prueba
predictions <- predict(rf_model, test)
table(predictions, test$Outcome)
```

#Area bajo la curva
```{r}
# Generar curva ROC y calcular área bajo la curva
roc_obj <- roc(response = data_diab$Outcome, predictor = predict(rf_model, data_diab))
auc(roc_obj) 

roc_data <- roc(data_diab$Outcome, predict(rf_model_cv, data_diab))
auc <- round(auc(roc_data), 4)
print(paste0("El área bajo la curva ROC es: ", auc))
```


#prueba de modelo KMEANS

```{r}

# Prueba de codo para seleccionar el número de clústeres óptimo

set.seed(123)
wss <- vector()
for (i in 1:15) wss[i] <- sum(kmeans(datos[,-1], centers = i)$withinss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares")

# Ejecutar kmeans con el número de clústeres óptimo
set.seed(123)
k <- 2 # número óptimo de clústeres obtenido en la prueba de codo
km <- kmeans(datos[,-1], centers = k, nstart = 25)

```

```{r}
# Renombrar los clusters
names(km$cluster) <- c("Cluster 1", "Cluster 2")

# Verificar los nuevos nombres de cluster
table(km$cluster)

# Gráfico de los clústeres
fviz_cluster(km, data = datos[,-1], geom = "point", stand = FALSE)

```









