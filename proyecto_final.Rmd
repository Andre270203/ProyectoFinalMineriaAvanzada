---
title: "Proyecto Final"
author: "Grupo AGMJ"
date: "12/3/2023"
output: html_document
---

#Algoritmos utilizado: Regresion logistica y RandomForest

```{r setup, include=FALSE}
#install.packages("knitr")
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

#librerias
```{r}
library(ggplot2)
library(GGally)
library(mvnTest)
library(vcd)
library(corrplot)
library(car)
library(MVN)
library(PASWR)
library(coin)
library(survival)
library(agricolae)
library(cvTools)
library(pROC)
library(boot)
library(randomForest)
library(caret)
library(factoextra)
```

#Carga DataSet
```{r}
data_diab <- read.csv("diabetes-dataset.csv", header = TRUE, dec = ".", sep = ",", na.strings = c("", "NA", "N/A", "NULL"))
data_diab <- na.omit(data_diab)

data_diab <- data.frame(data_diab)
data_diab$Outcome <- factor(data_diab$Outcome)
```

#Variables del DataSet
```{r}
str(data_diab)
```

#Analisis exploratorio
```{r}
EDA(data_diab$Pregnancies)
EDA(data_diab$Glucose)
EDA(data_diab$BloodPressure)
EDA(data_diab$SkinThickness)
EDA(data_diab$Insulin)
EDA(data_diab$BMI)
EDA(data_diab$DiabetesPedigreeFunction)
EDA(data_diab$Age)
```

#Analisis de Bigotes
```{r}
ggplot(data = data_diab, mapping = aes(x = Outcome, y = Pregnancies)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = Glucose)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = BloodPressure)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = SkinThickness)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = Insulin)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = BMI)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = DiabetesPedigreeFunction)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

ggplot(data = data_diab, mapping = aes(x = Outcome, y = Age)) +
geom_boxplot(aes(color = Outcome)) +
geom_point(aes(color = Outcome)) +
theme_bw() +
theme(legend.position = "null")

```

```{r}
# Prueba de normalidad de Shapiro-Wilk para cada variable independiente 
vars <- c("Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI", "DiabetesPedigreeFunction", "Age") 
sw_results <- data.frame(Variable = character(), p_valor = numeric(), Normalidad = character(), stringsAsFactors = FALSE) 
for (i in vars) { 
  p_val <- shapiro.test(data_diab[, i])$p.value 
  norm <- ifelse(p_val > 0.05, "Normal", "No Normal") 
  sw_results <- rbind(sw_results, data.frame(Variable = i, p_valor = p_val, Normalidad = norm)) 
} 
# Mostrar los resultados 
sw_results

royston_test <- mvn(data = data_diab[,-9], mvnTest = "royston")
royston_test$multivariateNormality

hz_test <- mvn(data = data_diab[,-9], mvnTest = "hz")
hz_test$multivariateNormality
```

# El modelo Mann-Whitney lo utilizamos para comparar las medianas de dos grupos independientes en una variable ordinal o continua no paramétrica.

# El modelo Kruskal-Wallis lo utilizamos para comparar las medianas de tres o más grupos independientes en una variable ordinal o continua no paramétrica.
```{r}
# Realizar la prueba de Mann-Whitney para datos no pareados
wilcox.test(data_diab$Glucose, data_diab$Pregnancies)

# Realizar la prueba de Kruskal-Wallis
kruskal.test(data_diab$BMI, data_diab$DiabetesPedigreeFunction)
```
#Test de Normalidad
```{r}
# Establecer los márgenes del gráfico
par(mfcol = c(2, 8), mar = c(2, 2, 2, 2), oma = c(2, 2, 2, 2))


# Generar histogramas para cada variable
for (k in 1:8) {
  j0 <- names(data_diab)[k]
  x0 <- seq(min(data_diab[, k]), max(data_diab[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(data_diab$Outcome)[i]
    x <- data_diab[data_diab$Outcome == i0, j0]
    hist(x, proba = T, col = grey(0.8), main = paste(i0), xlab = j0)
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}

# Establecer el título del gráfico
mtext("Histogramas de variables", outer = TRUE, cex = 1.5)
```

#Modelo de Correlacion
```{r}
correlations <- cor(data_diab[,1:8])
corrplot(correlations, method="circle")
```

#Modelo de analisis de regresion
```{r}
modelo <- glm(Outcome ~ ., data = data_diab, family = binomial)
summary(modelo)
```

#seleccion de variables funcion step
```{r}
step(modelo, direction = "backward")
```

#Division de DataSet
```{r}
set.seed(1)
row.number = createDataPartition(data_diab$Outcome, p = 0.6, list = FALSE)
train = data_diab[row.number,]
train = train[,-4]
test = data_diab[-row.number,]
test = test[,-4]
dim(train)
dim(test)

```

```{r}
# Modelo de regresión logistica
log_reg_model = glm(Outcome ~ ., data = train, family = binomial)

# Modelo de Random Forest
set.seed(123)
rf_model <- randomForest(x = train[1:7], y = train$Outcome, ntree = 100, mtry = 2)
```


#Validacion Cruzada
```{r}

cat("Regresión logistica", "\n", "\n")
# Validación cruzada con 10 pliegues
cv_log_reg <- cv.glm(train, log_reg_model, K = 10)

# Obtener la media y la desviación estándar del error de predicción
mean_error<- mean(cv_log_reg$delta) # media del error de predicción
sd_error<- sd(cv_log_reg$delta)     # desviación estándar del error de predicción

# Imprimir los resultados
cat("Media del error de predicción: ", mean_error*100,"%", "\n")
cat("Desviación estándar del error de predicción: ", sd_error*100, "\n")


cat("\n","\n", "Random Forest", "\n", "\n")

# Validación cruzada con Random Forest
ctrl <- trainControl(method = "cv", number = 10)
set.seed(123)
cv_results <- train(Outcome ~ ., data = train, method = "rf", trControl = ctrl)

# Obtener la media y la desviación estándar del error de predicción
mean_error_rf <- mean(cv_results$resample$Accuracy) # media del error de predicción
sd_error_rf <- sd(cv_results$resample$Accuracy) # desviación estándar del error de predicción

# Imprimir los resultados
cat("Media del error de predicción: ", mean_error_rf*100,"%", "\n")
cat("Desviación estándar del error de predicción: ", sd_error_rf*100, "\n")
```

#Area bajo la curva
```{r}
cat("Regresión logistica", "\n", "\n")

# Ajustar el modelo al conjunto de datos de prueba
pred_logreg <- predict(log_reg_model, test, type = "response")

# Calcular el área bajo la curva ROC utilizando el conjunto de datos de entrenamiento
auc_logreg <- roc(test$Outcome, pred_logreg)

# Imprimir el valor del área bajo la curva ROC
cat("Área bajo la curva ROC: ", auc_logreg$auc, "\n")


cat("\n","\n", "Random Forest", "\n", "\n")

# Obtener las predicciones del modelo para el conjunto de datos de prueba
pred_rf <- predict(rf_model, newdata = test, type = "response")

# Calcular el área bajo la curva ROC
auc_rf <- roc(response = test$Outcome, predictor = as.numeric(pred_rf))

# Imprimir el valor del área bajo la curva ROC
cat("Área bajo la curva ROC: ", auc_rf$auc)

```


#Resumen del modelo de regresión logistica
```{r}
cat("Regresión logistica","\n","\n")
summary(log_reg_model)
cat("\n","\n","Random forest","\n","\n")
summary(rf_model)
```

#Coeficientes de regresion logistica
```{r}

cat("coeficientes de regresión","\n","\n")
options(scipen = 999) #Para evitar que mis datos me salgan en notación
#científica
exp(cbind(OR=coef(log_reg_model),confint(log_reg_model)))

cat("\n","\n","factor de inflación de la varianza","\n","\n")
vif(log_reg_model)
```


#Matriz de confusion (Data: Test) 
```{r}
predictions_logreg <- ifelse(pred_logreg > 0.5, "1", "0")

reg_log.matriz <- confusionMatrix(factor(predictions_logreg), reference = test$Outcome)
cat("\nMatriz de Confusión - Regresión Logística\n")
cat("Este es el resultado de evaluar el modelo en el conjunto de datos de prueba:\n\n")

reg_log.matriz
```

```{r}
predictions_rf <- ifelse(as.numeric(pred_rf) > 0.5, "1", "0")

rf.matriz <- confusionMatrix(factor(predictions_rf, levels = levels(test$Outcome)), test$Outcome)

cat("\n\nMatriz de Confusión - Random Forest\n")
cat("Este es el resultado de evaluar el modelo en el conjunto de datos de prueba:\n\n")

rf.matriz

```